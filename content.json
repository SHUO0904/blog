{"meta":{"title":"HOME","subtitle":null,"description":null,"author":null,"url":"https://shuo0904.github.io/blog","root":"/blog/"},"pages":[{"title":"daily_Note","date":"2019-11-18T09:56:00.000Z","updated":"2019-11-18T09:57:50.590Z","comments":true,"path":"待发布-汇总/daily-Note.html","permalink":"https://shuo0904.github.io/blog/待发布-汇总/daily-Note.html","excerpt":"","text":"selenium –增加options.add_experimental_option(‘excludeSwitches’, [‘enable-automation’]) #隐藏脚本为selenium"},{"title":"selenium自动化框架搭建(一)","date":"2019-11-12T11:59:12.000Z","updated":"2019-11-14T01:24:56.320Z","comments":true,"path":"待发布-汇总/selenium自动化框架搭建-一.html","permalink":"https://shuo0904.github.io/blog/待发布-汇总/selenium自动化框架搭建-一.html","excerpt":"","text":"PageObject页面对象模式 一个页面建一个类，即对象，页面对象；每个页面都建对应的class，类中包含了页面的输入框、标题、元素等元素。测试代码中测试这个页面时，只需要调用这个页面类(页面对象)里的页面元素即可，这样可实现了将测试对象(页面对象)和测试脚本(用例脚本)分离；若元素ID等发生变化时，不需要去修改测试代码，只需要在页面类中修改即可，利于维护所有脚本。 页面对象设计模式可分为三层: 对象库层(基础层)：存放页面元素和一些特殊控件操作，driver，findelement，findelements 操作层(对象层)：里面封装元素属性、点击鼠标、点登陆等操作，需继承基础层 业务层(测试层)：调用对象层封装的(操作)方法，真正的实例化driver，完成测试用例的操作 当测试数据量大时，可以在上述基础上增加一层 数据层，用于存放测试数据，如下： 对象库层 逻辑层 业务层 数据层"},{"title":"selenium定位元素整理","date":"2019-11-16T07:31:08.000Z","updated":"2019-11-16T07:32:42.467Z","comments":true,"path":"待发布-汇总/selenium定位元素整理.html","permalink":"https://shuo0904.github.io/blog/待发布-汇总/selenium定位元素整理.html","excerpt":"","text":"selenium webdriver进行元素定位时，通过seleniumAPI官方介绍，获取页面元素的方式一共有以下八种方式，现按照常用→不常用的顺序分别介绍一下。 官方api地址：https://seleniumhq.github.io/selenium/docs/api/java/index.html 一、By.Id()在HTML中，ID属性–唯一标识一个元素的属性。selenium中，ID被作为首选的识别属性，因为这是最快的识别策略。 以百度主页为例，搜索框的HTML示例代码如下，其ID为kw； 1&lt;input id=&quot;kw&quot; name=&quot;wd&quot; class=&quot;s_ipt&quot; value=&quot;&quot; maxlength=&quot;255&quot; autocomplete=&quot;off&quot;&gt; 搜索框的ID是”kw”。 1&lt;input type=&quot;submit&quot; id=&quot;su&quot; value=&quot;百度一下&quot; class=&quot;bg s_btn&quot;&gt; 百度一下按钮的id是”su”。 在WebDriver中通过ID查找元素的java示例代码如下： 1234567891011121314 1 import org.openqa.selenium.By; 2 import org.openqa.selenium.WebDriver; 3 import org.openqa.selenium.chrome.ChromeDriver; 4 import org.testng.annotations.Test; 5 public class findElementByID &#123; 6 @Test 7 public void test() &#123; 8 WebDriver driver = new ChromeDriver(); //打开chrome浏览器 9 driver.get(&quot;http://www.baidu.com&quot;); //输入网址10 driver.findElement(By.id(&quot;kw&quot;)).sendKeys(&quot;selenium&quot;); //搜索框输入&quot;selenium&quot;11 driver.findElement(By.id(&quot;su&quot;)).click(); //点击百度一下，进行搜索12 driver.quit(); //关闭浏览器13 &#125;14 &#125; 示例代码详解： 1、指定WebDriver 为ChromeDriver。 2、打开百度主页。 3、通过ID为kw来查找搜索框，其中findElement（）方法通过By.id（）在页面上查找指定的ID元素，并将查找的结果执行sendkeys操作，输入要搜索的值。 4、在搜索框中输入字符串”selenium”。 5、通过ID为su来查找搜索按钮，并执行click点击操作。 6、触发搜索按钮的提交操作，进行搜索。 7、关闭浏览器，结束测试。 二、By.Name()在HTML中，name属性和ID属性功能基本相同，只是name属性不一定是唯一的。在selenium中，如果没有ID的话，首先考虑的就是name属性。 以豆瓣网的主页搜索框为例子，其搜索框的HTML代码如下： 1&lt;input type=&quot;text&quot; maxlength=&quot;60&quot; size=&quot;12&quot; placeholder=&quot;书籍、电影、音乐、小组、小站、成员&quot; name=&quot;q&quot; autocomplete=&quot;off&quot;&gt; 搜索框的name是”q”。 在WebDriver中通过Name查找元素的java示例代码如下： 12345678910111213141516 1 import org.openqa.selenium.By; 2 import org.openqa.selenium.WebDriver; 3 import org.openqa.selenium.WebElement; 4 import org.openqa.selenium.chrome.ChromeDriver; 5 import org.testng.annotations.Test; 6 public class findElementByName &#123; 7 @Test 8 public void test() &#123; 9 WebDriver driver = new ChromeDriver(); //打开chrome浏览器10 driver.get(&quot;http://www.douban.com&quot;); //输入网址11 WebElement serch=driver.findElement(By.name(&quot;q&quot;)); //生成WebElement实例对象serch12 serch.sendKeys(&quot;find element by name&quot;); //搜索框输入&quot;find element by name&quot;13 serch.submit(); //进行搜索14 driver.quit(); //关闭浏览器15 &#125;16 &#125; 示例代码详解： 1、指定WebDriver 为ChromeDriver。 2、打开豆瓣主页。 3、通过Name为q来调用findElemet()方法找到豆瓣主页的搜索框元素，并保存到WebElement实例对象中代码如下： WebElement search = driver.findElement(By.name(“q”)); 4、在搜索框中输入字符串find element by name 。 5、通过submit()，进行搜索。 6、结束测试，关闭浏览器。 注意：submit和click的区别。Click方法只适用于button，而submit可以用于提交表单。 三、By.Xpath() 这个方法是非常强大的元素查找方式，使用这种方法几乎可以定位到页面上的任意元素。在正式开始使用XPath进行定位前，我们先了解下什么是XPath。XPath是XML Path的简称，由于HTML文档本身就是一个标准的XML页面，所以我们可以使用XPath的语法来定位页面元素。 Xpath通过路径来定位控件，分为绝对路径和相对路径。绝对路径以单/号表示，相对路径则以//表示。当xpath的路径以/开头时，表示让Xpath解析引擎从文档的根节点开始解析。当xpath路径以//开头时，则表示让xpath引擎从文档的任意符合的元素节点开始进行解析。而当/出现在xpath路径中时，则表示寻找父节点的直接子节点，当//出现在xpath路径中时，表示寻找父节点下任意符合条件的子节点。弄清这个原则，就可以理解其实xpath的路径可以绝对路径和相对路径混合在一起来进行表示，想怎么玩就怎么玩。 假设我们现在以下图所示HTML代码为例，要引用对应的对象，XPath语法如下： 绝对路径写法(只有一种)，写法如下： 引用页面上的form元素(即源码中的第3行)：/html/body/form 下面是相对路径的引用写法： 查找页面根元素：// 查找页面上所有的input元素：//input 查找页面上第一个form元素内的直接子input元素(即只包括form元素的下一级input元素)：//form/input 查找页面上第一个form元素内的所有子input元素(只要在form元素内的input都算，不管还嵌套了多少个其他标签，使用相对路径表示，双//号)：//form//input 查找页面上第一个form元素：//form 查找页面上id为loginForm的form元素：//form[@id=’loginForm’] 查找页面上具有name属性为username的input元素：//input[@name=’username’] 查找页面上id为loginForm的form元素下的第一个input元素：//form[@id=’loginForm’]/input[1] 查找页面具有name属性为contiune并且type属性为button的input元素：//input[@name=’continue’][@type=’button’] 查找页面上id为loginForm的form元素下第4个input元素：//form[@id=’loginForm’]/input[4] 以百度主页为例，搜索框的HTML示例代码如下，其xpath为//*[@id=’’kw]。 在WebDriver中通过Xpath查找元素的java示例代码如下： 12345678910111213141516 1 import org.openqa.selenium.By; 2 import org.openqa.selenium.WebDriver; 3 import org.openqa.selenium.WebElement; 4 import org.openqa.selenium.chrome.ChromeDriver; 5 import org.testng.annotations.Test; 6 public class findElementByXpath &#123; 7 @Test 8 public void test() &#123; 9 WebDriver driver = new ChromeDriver(); //打开chrome浏览器10 driver.get(&quot;http://www.baidu.com&quot;); //输入网址11 WebElement serch=driver.findElement(By.xpath(&quot;//*[@id=&apos;kw&apos;&quot;)); //生成WebElement实例对象serch12 serch.sendKeys(&quot;find element by xpath&quot;); //搜索框输入&quot;find element by xpath&quot;13 serch.submit(); //进行搜索14 driver.quit(); //关闭浏览器15 &#125;16 &#125; 示例代码详解： 1、指定WebDriver 为ChromeDriver。 2、打开百度主页。 3、通过Xpath为//*[@id=’’kw]来调用findElemet()方法找到百度主页的搜索框元素，并保存到WebElement实例对象中代码如下： WebElement search = driver.findElement(By.xpath(“//*[@id=’’kw]”)); 4、在搜索框中输入字符串find element by xpath。 5、通过submit()，进行搜索。 6、结束测试，关闭浏览器。 四、By.tagName() 通过TagName来查找元素的方式与之前的通过ID或者Name查找元素的方式略有不同。其原因是同一个页面上具有相同的TagName的元素就会返回多个结果，因此建议在使用TagName为查找元素的条件时，使用findElements()来替代findElement()函数。 以126为例，TagName为input的HTML事例代码如下： 通过TagName为script的元素个数的示例代码如下 在WebDriver中查找TagName为input的元素个数的java示例代码如下： 123456789101112131415161718 1 import java.util.List; 2 3 import org.openqa.selenium.By; 4 import org.openqa.selenium.WebDriver; 5 import org.openqa.selenium.WebElement; 6 import org.openqa.selenium.chrome.ChromeDriver; 7 import org.testng.annotations.Test; 8 9 public class findElementByTagName &#123;10 @Test11 public void test() &#123;12 WebDriver driver = new ChromeDriver(); // 打开chrome浏览器13 driver.get(&quot;http://www.126.com&quot;); // 输入网址14 List&lt;WebElement&gt; allInputs = driver.findElements(By.tagName(&quot;input&quot;)); // 生成WebElement实例对象allInputs15 System.out.println(allInputs.size()); // 输出tagName为input的个数16 driver.quit(); // 关闭浏览器17 &#125;18 &#125; 示例代码详解： 1、指定WebDriver 为ChromeDriver。 2、通过TagName为input来调用findElements()方法，找到126主页上所有的input元素并保存到WebElement实例对象列表中，代码如下： List allInputs= driver.findElements(By.tagName(“input”)); 3、打印126主页上TagName为input的元素的数量 4、结束测试，关闭浏览器。 从html中我们可以看到，文本框和密码框的元素标签都是input，此时单靠tagName无法准确地得到我们想要的元素，需要结合type属性才能过滤出我们要的元素。 示例代码如下： 1234567891011121314151617181920212223 1 import java.util.List; 2 3 import org.openqa.selenium.By; 4 import org.openqa.selenium.WebDriver; 5 import org.openqa.selenium.WebElement; 6 import org.openqa.selenium.chrome.ChromeDriver; 7 import org.testng.annotations.Test; 8 9 public class findElementByTagName &#123;10 @Test11 public void test() &#123;12 WebDriver driver = new ChromeDriver(); // 打开chrome浏览器13 driver.get(&quot;http://www.126.com&quot;); // 输入网址14 List&lt;WebElement&gt; allInputs = driver.findElements(By.tagName(&quot;input&quot;)); // 生成WebElement实例对象allInputs15 System.out.println(allInputs.size()); // 输出tagName为input的个数16 for (WebElement e : allInputs) &#123; // 循环17 if (e.getAttribute(&quot;type&quot;).equals(&quot;text&quot;)) &#123; // 判断18 e.sendKeys(&quot;abcde&quot;); // 输入&quot;abcde&quot;19 &#125;20 &#125;21 driver.quit(); // 关闭浏览器22 &#125;23 &#125; 五、By.className()className属性是利用元素的css样式表所引用的伪类名称来进行元素查找的方法。 以淘宝主页搜索框为例，其HTML如下： 通过className获取搜索框的java代码如下： 1234567891011121314151617 1 import org.openqa.selenium.By; 2 import org.openqa.selenium.WebDriver; 3 import org.openqa.selenium.WebElement; 4 import org.openqa.selenium.chrome.ChromeDriver; 5 import org.testng.annotations.Test; 6 7 public class findElementByclassName &#123; 8 @Test 9 public void test() &#123;10 WebDriver driver = new ChromeDriver(); // 打开chrome浏览器11 driver.get(&quot;http://www.taobao.com&quot;); // 输入网址12 WebElement e = driver.findElement(By.className(&quot;search-combobox-input&quot;)); // 实例化对象13 e.sendKeys(&quot;find element by className&quot;); // 输入find element by className14 e.submit(); //搜索15 driver.quit(); // 关闭浏览器16 &#125; 17 &#125; 示例代码详解： 1、指定WebDriver 为ChromeDriver。 2、打开淘宝主页。 3、通过className为search-combobox-input来调用findElemet()方法找到淘宝主页的搜索框元素，并保存到WebElement实例对象中。 4、在搜索框中输入字符串find element by className。 5、通过submit()，进行搜索。 6、结束测试，关闭浏览器。 六、By.CssSelector()CssSelector，Selenium官网的Document里极力推荐使用CSS locator，而不是XPath来定位元素，原因是CSS locator比XPath locator速度快，特别是在IE下面（IE没有自己的XPath 解析器(Parser)）他比xpath更高效更准确更易编写，因为前端开发人员就是用CSS Selector设置页面上每一个元素的样式，无论那个元素的位置有多复杂，他都能定位到，那我们使用CSS Selector肯定也能非常精准的定位到页面Elements。 css定位可以分为四类：id、class、tagName、其他属性、路径。 1 #id方式 两种方式，可以在前面加上tag名称，也可以不加 driver.findElement(By.cssSelector(“#id_value”)) 相当于使用id语法的driver.findElement(By.id(“id_value”)) driver.findElement(By.cssSelector(“tag_name#id_value”)) 相当于使用xpath语法的driver.findElement(By.xpath(“//tag_name[@id=’id_value’]”)) 以百度主页为例，搜索框的HTML示例代码如下， 通过CssSelector的#id方式的java代码如下： 1`import` `org.openqa.selenium.By;``import` `org.openqa.selenium.WebDriver;``import` `org.openqa.selenium.WebElement;``import` `org.openqa.selenium.chrome.ChromeDriver;``import` `org.testng.annotations.Test;` `public` `class` `FindElemenByCssSelector &#123;`` ``@Test`` ``public` `void` `test() &#123;`` ``WebDriver driver = ``new` `ChromeDriver(); ``// 打开chrome浏览器`` ``driver.get(``&quot;http://www.baidu.com&quot;``); // 输入网址`` ``WebElement e = driver.findElement(By.cssSelector(``&quot;#kw&quot;``)); ``// 实例化对象`` ``e.sendKeys(``&quot;find element by CssSelector&quot;``); ``// 输入find element by CssSelector`` ``driver.findElement(By.cssSelector(``&quot;input#su&quot;``)).click();``// 点击百度一下`` ``driver.quit(); ``// 关闭浏览器`` ``&#125;``&#125;` 示例代码详解： 实例化对象一行，使用CssSelector中的#id方式 点击百度一下那一行，使用CssSelector中的tagName#id方式 2 class方式 两种方式，前面加上tag名称，也可以不加。如果不加tag名称时，点不能省略。 driver.findElement(By.cssSelector(“.class_value”)) driver.findElement(By.cssSelector(“tag_name.class_value”)) 有的class_value比较长，而且中间有空格时，不能把空格原样写进去，那样不能识别。这时，空格用点代替，前面要加上tag_name。 如下driver.findElement(By.cssSelector(“tag_name.class_value1.calss_value2.class_value3”)) 以百度主页为例，搜索框的HTML示例代码如下 通过CssSelector的.class方式的java代码如下： 1`import` `org.openqa.selenium.By;``import` `org.openqa.selenium.WebDriver;``import` `org.openqa.selenium.WebElement;``import` `org.openqa.selenium.chrome.ChromeDriver;``import` `org.testng.annotations.Test;` `public` `class` `FindElemenByCssSelector &#123;`` ``@Test`` ``public` `void` `test() &#123;`` ``WebDriver driver = ``new` `ChromeDriver(); ``// 打开chrome浏览器`` ``driver.get(``&quot;http://www.baidu.com&quot;``); // 输入网址`` ``WebElement e = driver.findElement(By.cssSelector(``&quot;.s_ipt&quot;``)); ``// 实例化对象`` ``e.sendKeys(``&quot;find element by CssSelector&quot;``); ``// 输入find element by CssSelector`` ``driver.findElement(By.cssSelector(``&quot;input.bg.s_btn&quot;``)).click();``// 点击百度一下`` ``driver.quit(); ``// 关闭浏览器`` ``&#125;``&#125;` 示例代码详解： 其中实例化一行，使用.class方式获取对象 点击百度一下一样，使用tagName.class_value1.class_value2方式获取对象。 3 tagName方式 driver.findElement(By.cssSelector(“input”) 其中tagName是input 4 根据元素属性 1)精准匹配： [A] driver.findElement(By.cssSelector(“input[name=username]”));属性名=属性值,id,class,等都可写成这种形式 [B] driver.findElement(By.cssSelector(“input[type=’submit’][value=’Login’]”));多属性 2)模糊匹配：（正则表达式匹配属性） [A] ^= driver.findElement(By.cssSelector(Input[id ^=’ctrl’]));匹配到id头部 如ctrl_12 [B] $= driver.findElement(By.cssSelector(Input[id $=’ctrl’]));匹配到id尾部 如a_ctrl [C] *= driver.findElement(By.cssSelector(Input[id *= ‘ctrl’]));匹配到id中间如1_ctrl_12 5 子元素方式**** 12345678&lt;form id=&quot;form&quot; class=&quot;fm&quot; name=&quot;f&quot;&gt; &lt;span id=&quot;s_kw_wrap&quot; class=&quot;bg s_ipt_wr quickdelete-wrap&quot;&gt; &lt;input id=&quot;kw&quot; class=&quot;s_ipt&quot; type=&quot;text&quot; autocomplete=&quot;off&quot; maxlength=&quot;100&quot; name=&quot;wd&quot;&gt; &lt;/span&gt; &lt;span id=&quot;s_btn_wr&quot; class=&quot;btn_wr s_btn_wr bg&quot;&gt; &lt;input id=&quot;su&quot; class=&quot;btn self-btn bg s_btn&quot; type=&quot;submit&quot; value=&quot;百度一下&quot;&gt; &lt;/span&gt;&lt;/form&gt; 以上代码是百度首页搜索输入框和按钮的html，下面讲解以此为例 1)子元素 A&gt;B WebElement input= driver.findElement(By.cssSelector(“form&gt;span&gt;input”));//搜索输入框 2)后代元素 A空格B WebElement input= driver.findElement(By.cssSelector(“form input”));//搜索输入框 3)第一个后代元素 :first-child WebElement span= driver.findElemet(By.cssSelector(“form :first-child”));//冒号前有空格，定位到form下所有级别的第一个子元素 可定位到三个元素：&lt;span id=”s_kw_wrap”…/&gt; &lt;input id=”kw”…./&gt; &lt;input id=”su”………/&gt; WebElement span= driver.findElemet(By.cssSelector(“form input:first-child”));//冒号前无空格，定位到form下所有级别的第一个input元素 可定位到两个元素：&lt;input id=”kw”…./&gt; &lt;input id=”su”………/&gt; WebElement span= driver.findElemet(By.cssSelector(“form&gt;span:first-child”));//冒号前无空格，定位到form直接子元素中的第一个span元素 可定位到一个元素：&lt;span id=”s_kw_wrap”…/&gt; 4)最后一个子元素 :last-child [类同:first-child] WebElement userName = driver.findEleme(By.cssSelector(“form :last-child”));//冒号前有空格，定位到form下所有级别的第一个子元素 5)第2个子元素 :nth-child(N) [类同:first-child] WebElement userName = driver.findElemet(By.cssSelector(“form#form :nth-child(2)”));//冒号前有空格，定位到form下所有级别的第二个子元素 七、By.linkText()这个方法比较直接，即通过超文本链接上的文字信息来定位元素，这种方式一般专门用于定位页面上的超文本链接。 以百度主页为例，搜索框的HTML示例代码如下 通过linkTest方式的java代码如下： 1`import` `org.openqa.selenium.By;``import` `org.openqa.selenium.WebDriver;``import` `org.openqa.selenium.WebElement;``import` `org.openqa.selenium.chrome.ChromeDriver;``import` `org.testng.annotations.Test;` `public` `class` `FindElemenByCssSelector &#123;`` ``@Test`` ``public` `void` `test() &#123;`` ``WebDriver driver = ``new` `ChromeDriver(); ``// 打开chrome浏览器`` ``driver.get(``&quot;http://www.baidu.com&quot;``); // 输入网址`` ``WebElement a= driver.findElement(By.linkText(``&quot;新闻&quot;``));`` ``a.click();`` ``&#125;``&#125;` 八、By.partialLinkText()这个方法是上一个方法的扩展。当你不能准确知道超链接上的文本信息或者只想通过一些关键字进行匹配时，可以使用这个方法来通过部分链接文字进行匹配。代码如下： 1`import` `org.openqa.selenium.By;``import` `org.openqa.selenium.WebDriver;``import` `org.openqa.selenium.WebElement;``import` `org.openqa.selenium.chrome.ChromeDriver;``import` `org.testng.annotations.Test;` `public` `class` `FindElemenByCssSelector &#123;`` ``@Test`` ``public` `void` `test() &#123;`` ``WebDriver driver = ``new` `ChromeDriver(); ``// 打开chrome浏览器`` ``driver.get(``&quot;http://www.baidu.com&quot;``); // 输入网址`` ``WebElement a= driver.findElement(By.partialLinkText(``&quot;新&quot;``));`` ``a.click();`` ``&#125;``&#125;` 参考文档：http://www.cnblogs.com/qingchunjun/p/4208159.html ​ https://www.cnblogs.com/sylvia-liu/p/4469597.html 版权所有，欢迎转载，转载请注明出处：http://www.cnblogs.com/hustar0102/"}],"posts":[{"title":"Seesion和Cookie的区别","slug":"Seesion和Cookie的区别","date":"2019-11-26T09:41:43.000Z","updated":"2019-11-26T12:03:27.292Z","comments":true,"path":"2019/11/26/Seesion和Cookie的区别/","link":"","permalink":"https://shuo0904.github.io/blog/2019/11/26/Seesion和Cookie的区别/","excerpt":"","text":"区别 Session 是存储在服务端，Cookie是存储在浏览器中。使用中存在Session和Cookie函数，可以直接使用 Cookie Cookie的诞生是为了能让无状态的HTTP报文带上一些特殊的数据，让服务端能够辨识请求的身份。简单点说，是浏览器上的一个key-value存储对象，可通过浏览器开发者工具(F12)看到Cookie的内容 写入数据方式Cookie写入数据的方式是通过HTTP返回报文Header部分Set-Cookie字段来设置，一个带有写Cookie指令的HTTP返回的报文如下： 12345HTTP/1.1 200 OKSet-Cookie: SESSIONID=e13179a6-2378-11e9-ac30-fa163eeeaea1; Path=/Transfer-Encoding: chunkedDate: Tue, 29 Jan 2019 07:12:09 GMTServer: localhost 上述报文Set-Cookie指示浏览器设置 key 为 SEESSIONID，value 为SESSIONID=e13179a6-2378-11e9-ac30-fa163eeeaea1的 Cookie 获取数据方式 浏览器在发送请求的时候会检查当前域已经设置的Cookie，在HTTP请求报文 Header 部分的Cookie 字段里面带上 Cookie的信息。下面为一段HTTP报文： 1234567891011GET http://10.0.1.24:23333/ HTTP/1.1Host: 10.0.1.24:23333Connection: keep-alivePragma: no-cacheCache-Control: no-cacheUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8Accept-Encoding: gzip, deflateAccept-Language: zh-CN,zh;q=0.9,en;q=0.8Cookie: SESSIONID=e13179a6-2378-11e9-ac30-fa163eeeaea1 从最后的Cookie 字段看到，浏览器请求时带上了 key为SESSIONID，value为e13179a6-2378-11e9-ac30-fa163eeeaea1的数据，后端直接解析HTTP报文就能获取Cookie的内容 Session Session 在代码里面指记录客户端状态的一个存储对象，是同一个客户端请求共享的数组。这个存储对象可以是文件、缓存系统、数据库。 现在假设使用redis来实现Session功能，那么就要求浏览器每次请求都要带一个相同的字符串作为身份信息，对应redis的key ，redis value则为Session数组序列化的内容。 浏览器中Session和Cookie的关系，通过Cookie传递这个身份信息，简单流程如下： 客户端请求 服务端检测Header，发现没有Cookie，于是生成一个UUID 服务端处理数据，把部分数据（登录信息）存储到redis里面，UUID为key，用户id为value 返回报文中，增加Set-Cookie字段，内容带上UUID 浏览器收到报文，把UUID写进浏览器存储里面 浏览器再次请求，带上当前的域的Cookie，就是这个UUID 服务端通过Cookie字段获取到该UUID，去redis里面获取用户的信息 问题：若禁止Cookie 是否可以获取 Session从上面可以知道，SESSIONID是通过Cookie来传递，若禁止Cookie禁止了，还能获取SESSIONID吗？答案是可以的。既然Cookie禁止了，我们可以用参数的方法传递SESSIONID，后端返回的时候，增加一个返回参数，叫SESSIONID，然后前端存储到localstorage里面。前端请求的时候，去localstorage获取SESSIONID，在请求参数里增加一个参数，后端Session处理，先尝试从Cookie中获取SESSIONID，若获取不到，再尝试从请求参数中获取SESSIONID。这样，就算禁止Cookie也是能获取Session的。 总结Session和Cookie 区别： Cookie 是浏览器端的存储对象，有容量限制，通过HTTP报文与后端交互 Session 是服务端的存储对象，实现的方式有文件系统，缓存系统、数据库 Session和Cookie 联系： Session和Cookie是为了实现HTTP请求带上客户端状态的方法 Session 大多数情况下都是依赖Cookie来传递 Seesion Id 手动实现Session (python) 转载自：微信公众号(Java技术人)","categories":[],"tags":[]},{"title":"进程与线程的理解","slug":"进程与线程的理解","date":"2019-11-26T04:28:20.000Z","updated":"2019-11-26T07:46:43.751Z","comments":true,"path":"2019/11/26/进程与线程的理解/","link":"","permalink":"https://shuo0904.github.io/blog/2019/11/26/进程与线程的理解/","excerpt":"","text":"进程（process）和线程（thread）是操作系统的基本概念，但是它们比较抽象，不容易掌握。最近，我读到一篇材料，发现有一个很好的类比，可以把它们解释地清晰易懂。 计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。 假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。 进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。 一个车间里，可以有很多工人。他们协同完成一个任务。 线程就好比车间里的工人。一个进程可以包括多个线程。 车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存 可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。 一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫“互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域。 还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。 这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法叫做“信号量”（Semaphore），用来保证多个线程不会互相冲突。不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。 操作系统的设计，因此可以归结为三点：（1）以多进程形式，允许多个任务同时运行；（2）以多线程形式，允许单个任务分成不同的部分运行；（3）提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 转载自 http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html","categories":[],"tags":[]},{"title":"【Python】正则表达式常用整理","slug":"正则表达式常用整理","date":"2019-11-11T08:02:31.000Z","updated":"2019-11-12T08:05:34.946Z","comments":true,"path":"2019/11/11/正则表达式常用整理/","link":"","permalink":"https://shuo0904.github.io/blog/2019/11/11/正则表达式常用整理/","excerpt":"","text":"正则表达式 正则表达式（regular expression）是对字符串操作一种逻辑公式，用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，对字符串一种过滤逻辑。最简单正则表达式是普通字符串，可以匹配其自身。如，正则表达式‘hello’可以匹配字符串‘hello’ 正则表达式不是一个程序，是用于处理字符串的一种模式；使用时需使用支持正则表达式工具，如：Linux中的awk，sed，grep，或编程语言中的Perl，Python，Java等等 字符组:[字符组]，在同一个位置可能出现的各种字符组成一个字符组，在正则表达式中用[ ]表示；字符分为很多类，比如：数字，字母，标点等 正则 待匹配字符 匹配结果 说明 [0123456789] 8 True 在一个字符组里枚举合法的所有字符，字符组里的一个字符和“待匹配字符”相同都视为可以匹配 [0123456789] a False 由于字符组中没有“a”字符，无匹配结果 [0-9] 7 True 可以用 - 表示范围，[0-9]和[0123456789]是一个意思 [a-z] s True 匹配所有的小写字母 [A-Z] B True 匹配所有大写字母 [0-9a-fA-F] e True 匹配数字，大小写a~f，可用来验证十六进制字符 常用限定符 语法 说明 *? 重复任意次，但尽可能少重复 +？ 重复1次或更多次，但尽可能少重复 ？？ 重复0次或1次，尽可能少重复 {n,m}? 重复n到m次，但可能少重复 {n,}? 重复n次以上，但尽可能少重复 常用表达式全集 字 符 描述 \\ 将一个字符标记为一个特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符。如：“n”匹配字符“n”。”\\n”匹配一个换行符。“\\\\”匹配”\\“。“\\(”匹配“（”。 ^ 匹配输入字符串的开始位置。 $ 匹配输入字符串的结束位置。 * 匹配前面的子表达式零次或多次。如：zo* 能匹配“z”及“zoo”，* 等价于{0，} + 匹配前面的子表达式一次或多次。如：zo+ 能匹配”zo“及”zoo“，但不能匹配”z“。+等价于{1，} ？ 匹配前面的字表达式零次或一次。如：do(es)? 能匹配 does 或 does中的do。？等价于{0,1} {n} n是一个非负整数。匹配确定的n次。如：o{2} 不能匹配bob中的o，但能匹配 food 中的两个o {n,} n是一个非负整数。至少匹配n次。如：o{2，} 不能匹配 ‘Bob’中的‘o’，但能匹配到 ‘foooooood’中所有o。“o{1,}等价于“o+”。”o{0,}“等价于”o*“ {n,m} m和n均为非负整数，其中n&lt;=m。最少匹配n次且最多匹配m次。如：”o{1,3}”将匹配“fooooooood”中前三个o。“o{0,1}”等价于“o?”。注意逗号和两个数之间不能有空格。 ？ 当该字符紧跟在任何一个其它限制符(*,+,?,{n},{n,},{n,m})后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。如：字符串”ooooo”，”o+?”将匹配单个”o”，而”o+”将匹配所有”o” . 匹配除 “\\n”之外的任何单个字符。要匹配包括“\\n”在内的任何字符，使用“(.|\\n)”的模式 (pattern） 匹配pattern并获取这一匹配 (?:pattern） 匹配pattern但不获取匹配结果，非获取匹配。如：industr(?:y|ies) 比 “industry|industries”简略 (?=pattern 正向肯定预查，任何匹配pattern的字符串开始匹配查找字符串。如：Window(?=95|98|NT|2000) 能匹配 Windows2000 中的 Windows，但不能匹配”Window3.1”中的”Windows“。在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern） 正向否定预查，任何不匹配pattern的字符串开始匹配查找字符串。如：Windows(?!95|98|NT|2000) 能匹配“Windows3.1”中的“Windows”，不能匹配“Windows2000”中的“Windows”。在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始 (?&lt;=patt) 反向肯定预查，与正向肯定预查类似，只是方向相反。如：”(?&lt;95|98|NT|2000)Windows”能匹配”2000Windows”中的”Windows“，但不能匹配”3.1Windows”中的”Windows” (?&lt;!patt) 反向否定预查，与正向否定预查类似，只是方向相反。如：“(?&lt;95|98|NT|2000)Windows”能匹配”3.1Windows”中的”Windows”，但不能匹配”2000Windows”中的“Windows” x|y 匹配x或y。如：“z|food”能匹配”z”或”food”。”(z|f)food”则匹配”zood”或”food” [xyz] 字符集合。匹配所包含的任意一个字符。如，”[abc]”可匹配”plain”中的”a” [^xyz] 负值字符集合。 匹配未包含的任意字符。如：”[^abc]”可匹配”plain”中的”p” [a-z] 字符范围。匹配指定范围内的任意字符。如：”[a-z]”可以匹配”a”到”z”范围内的任意字符 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。如：”[^a-z]”可以匹配任何不在”a”到”z”范围内的任意字符 \\b 匹配一个单词边界，也就是单词和空格间的位置。如：”er\\b”可以匹配”never”中的”er”，不能匹配”verb”中的“er” \\B 匹配非单词边界。”er\\B”能匹配”verb”中的“er”，但不能匹配”never”中的”er” \\cx 匹配由x指明的控制字符。如：\\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将C视为一个原义的”c”字符 \\d 匹配一个数字字符，等价于[0-9] \\D 匹配一个非数字字符，等价于[^0-9] \\f 匹配一个换页符，等价于\\x0c和\\cL \\n 匹配一个回车符，等价于\\x0d和\\cM \\r 匹配一个回车符，等价于\\x0d和\\cM \\s 匹配任何空白字符，包括空格、制表符、换页符等待，等价于[\\f\\n\\r\\t\\v] \\S 匹配任何非空白字符，等价于[^\\f\\n\\r\\t\\v] \\t 匹配一个制表符，等价于\\x09和\\cl \\v 匹配一个垂直制表符，等价于\\x0b和\\cK \\w 匹配包括下划线的任何单词字符，等价于“[A-Za-z0-9]” \\W 匹配任何非单词字符，等价于”[^A-Za-z0-9]” \\xn 匹配n，其中n为十六进制转义值。十六进制转义值必须为确定的两个数长。如：”\\x41”匹配”A”，“\\x041”等价于”\\x04&amp;1”，可以使用ASCII编码 \\num 匹配num，其中num是一个正整数。对获取的匹配引用。如：”(.)\\1”匹配两个连续的相同字符 \\n 标识一个八进制转义值或一个向后引用。如果*n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。 *nml* 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。 **nm** 标识一个八进制转义值或一个向后引用。如果*nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm*。 \\un 匹配n，其中n是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配版权符号（©）。 用户名 /^[a-z0-9_-]{3,16}$/ 密码 /^[a-z0-9_-]{6,18}$/ 十六进制值 /^#?([a-f0-9]{6}|[a-f0-9]{3})$/ 电子邮箱 /^([a-z0-9_.-]+)@([\\da-z.-]+).([a-z.]{2,6})$//^[a-z\\d]+(.[a-z\\d]+)*@(\\da-z?)+(.{1,2}[a-z]+)+$/ URL /^(https?://)?([\\da-z.-]+).([a-z.]{2,6})([/\\w .-])/?$/ HTML 标签 /^&lt;([a-z]+)([^&lt;]+)(?:&gt;(.)&lt;/\\1&gt;|\\s+/&gt;)$/ 删除代码\\注释 (?&lt;!http:|\\S)//.*$ Unicode编码中的汉字范围 /^[\\u2E80-\\u9FFF]+$/ 参考链接 http://tool.oschina.net/uploads/apidocs/jquery/regexp.html","categories":[],"tags":[]},{"title":"爬虫常用解析","slug":"爬虫常用解析","date":"2019-11-10T10:52:30.000Z","updated":"2019-11-10T12:18:45.824Z","comments":true,"path":"2019/11/10/爬虫常用解析/","link":"","permalink":"https://shuo0904.github.io/blog/2019/11/10/爬虫常用解析/","excerpt":"","text":"Xpath解析 (lxml) 使用前，需进行安装lxml，pip install lxml 常用： wiki123456789101112131415161718nodename # 选取nodename节点所有子节点 xpath(&apos;//div&apos;) # 选取了所有div节点 / # 从根节点选取 xpath(&apos;/div&apos;) # 从根节点上选取div节点 // # 选取所有的当前节点,不考虑位置 xpath(&apos;//div&apos;) # 选取所有的div节点 . # 选取当前节点 xpath(&apos;./div&apos;) # 选取当前节点下的div节点 .. # 选取当前节点父节点 xpath(&apos;..&apos;) #回到上一个节点 @ # 选取属性 xpath(&apos;//@class&apos;) #选取所有的class属性//div[@class=&apos;song&apos;] # 找到class属性值为song的div标签//div[@class=&apos;tang&apos;]/url/li[2]/a # 找到class属性值为tang的div的直系子标签url下第二个标签li直系子标签a//a[@href=&apos;&apos;and @class=&apos;du&apos;] # 找到href属性值为空且class属性值为du的a标签//div[contains(@class, &apos;ng&apos;)] # 模糊查询//div[starts-with(@class,&apos;ta&apos;)] # 模糊查询//div[@class=&apos;song&apos;]/p[1]/text() # / 表示获取某个标签下的文本内容//div[@class=&apos;tang&apos;]//text() # // 表示获取某个标签下的文本内容和所有子标签下的文本内容//div[@class=&apos;tang&apos;]//li[2]/a/@href #取属性 函数 用法 解释starts-with xpath(‘//div[starts-with(@id,”ma”)]‘) # 选取id值以ma开头的div节点contains xpath(‘//div[contains(@id,”ma”)]‘) # 选取id值包含ma的div节点text() xpath(‘//div[contains(text(),”ma”)]‘) # 选取节点文本包含ma的div节点 如： 1234567891011# 先导包from lxml import etree# 将html文档或者xml文档转换成一个etree对象，然后调用对象中的方法查找指定的节点# 1. 本地文件tree = etree.parse(文件名)tree.xpath(\"xpath表达式\")# 2. 网络数据tree = etree.HTML(网页内容字符串)tree.xpath(\"xpath表达式\") Beautiful Soup 解析 使用前，需安装beautifulsoup，pip install beautifulsoup4 Beautiful Soup 支持python标准库中的HTML解析器，也可使用第三方解析器，如lxml 常用： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# 根据标签名查找 - soup.a 只能找到第一个符合要求的标签# 获取属性 - soup.a.attrs 获取a所有的属性和属性值，返回一个字典 - soup.a.attrs[&apos;href&apos;] 获取href属性 - soup.a[&apos;href&apos;] 也可简写为这种形式# 获取内容 - soup.a.string - soup.a.text - soup.a.get_text() 注意:如果标签还有标签，那么string获取到的结果为None，而其它两个，可以获取文本内容# find：找到第一个符合要求的标签 - soup.find(&apos;a&apos;) 找到第一个符合要求的 - soup.find(&apos;a&apos;, title=&quot;xxx&quot;) - soup.find(&apos;a&apos;, alt=&quot;xxx&quot;) - soup.find(&apos;a&apos;, class_=&quot;xxx&quot;) - soup.find(&apos;a&apos;, id=&quot;xxx&quot;)# find_all：找到所有符合要求的标签 - soup.find_all(&apos;a&apos;) - soup.find_all([&apos;a&apos;,&apos;b&apos;]) 找到所有的a和b标签 - soup.find_all(&apos;a&apos;, limit=2) 限制前两个# 根据选择器选择指定的内容 select:soup.select(&apos;#feng&apos;) - 常见的选择器：标签选择器(a)、类选择器(.)、id选择器(#)、层级选择器 - 层级选择器： div .dudu #lala .meme .xixi 下面好多级 div &gt; p &gt; a &gt; .lala 只能是下面一级 注意:select选择器返回永远是列表，需要通过下标提取指定的对象------------------------------------------------------------------------------------------------ ------------------------------------------------------------------------------------------------from bs4 import BeautifulSoupsoup=BeautifulSoup(html_doc,&apos;lxml&apos;)#字符串：即标签名print(soup.find_all(&apos;b&apos;))#正则表达式import reprint(soup.find_all(re.compile(&apos;^b&apos;))) #找出b开头的标签，结果有body和b标签# 列表：如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签:print(soup.find_all([&apos;a&apos;,&apos;b&apos;]))#True：可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点print(soup.find_all(True))for tag in soup.find_all(True): print(tag.name)#方法:如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 ,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False-------------------------------------------------------------------------------------------------注意：关键字是class_，class_=value,value可以是五种选择器之一print(soup.find_all(&apos;a&apos;,class_=&apos;sister&apos;)) # 查找类为sister的a标签print(soup.find_all(&apos;a&apos;,class_=&apos;sister ssss&apos;)) # 查找类为sister和sss的a标签，顺序错误也匹配不成功print(soup.find_all(class_=re.compile(&apos;^sis&apos;))) # 查找类为sister的所有标签-------------------------------------------------------------------------------------------------#attrsprint(soup.find_all(&apos;p&apos;,attrs=&#123;&apos;class&apos;:&apos;story&apos;&#125;))-------------------------------------------------------------------------------------------------#text 值可以是：字符，列表，True，正则print(soup.find_all(text=&apos;Elsie&apos;))print(soup.find_all(&apos;a&apos;,text=&apos;Elsie&apos;))-------------------------------------------------------------------------------------------------#limit参数：如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果print(soup.find_all(&apos;a&apos;,limit=2))-------------------------------------------------------------------------------------------------#recursive 调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=Falseprint(soup.html.find_all(&apos;a&apos;))print(soup.html.find_all(&apos;a&apos;,recursive=False))-------------------------------------------------------------------------------------------------#tag：像调用 find_all() 一样调用tag find_all() 几乎是Beautiful Soup中最常用的搜索方法,所以我们定义了它的简写方法. BeautifulSoup 对象和 tag 对象可以被当作一个方法来使用~# 下面两行代码是等价的:soup.find_all(&quot;a&quot;)soup(&quot;a&quot;)# 这两行代码也是等价的:soup.title.find_all(text=True)soup.title(text=True)-------------------------------------------------------------------------------------------------#find_all() 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个&lt;body&gt;标签,那么使用 find_all() 方法来查找&lt;body&gt;标签就不太合适, 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法soup.find_all(&apos;title&apos;, limit=1)# [&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;]soup.find(&apos;title&apos;)# &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;#find() 方法直接返回结果.find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 Noneprint(soup.find(&quot;nosuchtag&quot;))# None 如： 12345678910from bs4 import BeautifulSoup# 转化本地文件soup = BeautifulSoup(open('本地文件'), 'lxml')# 转化网络文件soup = BeautifulSoup('字符串类型或者字节类型', 'lxml')# 从文档中获取所有文字内容:print(soup.get_text()) 正则表达式解析 使用正则表达式进行提起，如： 1234pattern = re.compile('&lt;dd&gt;.*?board-index.*?&gt;(\\d+)&lt;/i&gt;.*?src=\"(.*?)\".*?name\"&gt;&lt;a' +'.*?&gt;(.*?)&lt;/a&gt;.*?star\"&gt;(.*?)&lt;/p&gt;.*?releasetime\"&gt;(.*?)&lt;/p&gt;' +'.*?integer\"&gt;(.*?)&lt;/i&gt;.*?fraction\"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;', re.S)items = re.findall(pattern, html)","categories":[],"tags":[]},{"title":"【Python】 requests请求","slug":"requests-python","date":"2019-10-30T12:25:22.000Z","updated":"2019-11-01T09:41:38.470Z","comments":true,"path":"2019/10/30/requests-python/","link":"","permalink":"https://shuo0904.github.io/blog/2019/10/30/requests-python/","excerpt":"","text":"requests.post requests.post() 进行POST请求，传入报文的参数有2个，一个是data，一个是json 常见的form表单可以直接使用data参数进行报文提交，data的对象是python中的字典类型 最新存在payload报文，是一种json格式的报文，传入的报文对象需格式 12request.post(url,data=json.dumps(data))request.post(url,json=data) //json参数会自动将字典类型的对象转换为json格式 若data传递的参数为字符串，如json.dumps(payload),则request对参数进行url编码，所以data传字符串时，需要在header中指定Content-Type，如headers={“Content-Type”: “application/json”} 如果data传递的是字典、元组组成的列表或列表作为值的字典，则request对参数进行url编码，Content-Type的值为application/x-www-form-urlencoded content-type详解 http协议是建立在tcp/ip协议之上的应用层协议，主要包括三个部分，状态行，头部信息，消息主体。对应一个Http请求就是：请求行，请求头，请求体。 协议规定post提交数据，必须包含在消息主体中entiy-body中，但是协议并没有规定数据使用什么编码方式，开发者可以自己决定消息主体的格式。 数据发送出去后，需要接收 服务端解析成功，一般服务端会根据content-type 字段获取参数是怎么编码的，然后对应去解码 application/x-www-form-urlencoded,在最开始的请求方式中，请求参数都是放在url中，表单提交的时候，是以key=&amp;value=的方式写在url后面，是浏览器表单提交的默认方式 multipart/form-data,此种方式多用于文件上传，表单数据都保存在http的正文部分，各个表单项之间用bounday分开 application/json,与服务端消息主体是序列化的json字符串。目前比较常用，且spring对这个content-type上传的数据有很好的支持，对RestApi有很好的适配","categories":[],"tags":[]},{"title":"REST 和 RESTful API","slug":"api","date":"2019-10-29T11:48:08.000Z","updated":"2019-10-30T12:23:16.457Z","comments":true,"path":"2019/10/29/api/","link":"","permalink":"https://shuo0904.github.io/blog/2019/10/29/api/","excerpt":"","text":"Rest Rest是 REpresentational State Transfer，即表现层状态转化。 “表现层”指“资源”的“表现层“。把“资源”具体呈现出来的形式，叫做它的“表现层”。 所谓”资源“，指网络中一个实体或者说网络上的一个具体信息。如:文本、图片等。 所谓“转移”，代表客户端和服务器一个互动过程，过程中，涉及数据和状态的变化。 互联网通信协议HTTP协议，是一个无状态的协议。这意味着，所有的状态都保存在服务器端。若客户端想要操作服务器，需通过某种手段，让服务换发生“状态转化”(State Transfer)。而这种转化是建立在表现层之上，叫做“表现层状态转化” 客户端用到的手段，是HTTP协议中的四个操作方式的动词：GET、POST、PUT、DELETE，分别对应四种基本操作，GET用来获取资源，POST用来新建资源(可用户更新资源)，PUT用来更新资源，DELETE用来删除资源。URL定位资源，直接映射到HTTP中已实现的GET，POST，Delete，PUT方法 REST成熟度的四个层次 第一个层次的web服务，是使用HTTP作为传输方式，实际上远程方法调用(RPC)的具体形式，SOAP和XML-RPC属于此类 第二个层次的web服务，引入了资源的概念，每个资源有对应的标识符和表达。 第三个层次的web服务，使用不同的HTTP方法进行不同 操作，并且使用HTTP状态码表示不同的结果。如:HTTP和Get方法来获取资源、DELETE方法来删除资源 第四个层次的web服务，使用HATEOAS,在资源的表达中包含了链接信息。客户端可根据链接发现可执行的动作 Restful Api REST描述的是网络中client和server的一种交互形式；RESTful API是一种REST风格的网络 URL的根路径，如：http://api.****.com/v1 需要有api版本信息，如：v1 URL中使用名词指定资源，不用动词，且推荐使用复数，如：http://api.****.com/v1/books 使用HTTP协议里的动词来实现资源的添加，修改，删除，更新。包括，GET、POST、PUT、DELETE 使用正确的HTTP Status Code返回状态码，包括：2××=success(成功)、3××=Redirect(重定向)、4××=客户端错误、5××=服务端错误 综上，RESTful API是无状态，请求URL=动作(GET/POST/PUT/DELETE)+资源，响应使用精确的状态码和JSON格式数据","categories":[],"tags":[]},{"title":"Git 介绍和使用","slug":"Git","date":"2019-10-26T10:01:58.000Z","updated":"2019-10-27T08:33:22.023Z","comments":true,"path":"2019/10/26/Git/","link":"","permalink":"https://shuo0904.github.io/blog/2019/10/26/Git/","excerpt":"","text":"Git 介绍 git是分布式版本控制系统，SVN是集中式版本控制系统 集中式版本控制系统，版本库是集中存放在中央服务器，每次编写、修改、提取、上传等操作，首先需从中央服务器取得最新的版本，后进行编写等，完成后重新推送到中央服务器。且必须联网才能工作。 分布式版本控制系统，无中央服务器，项目组内成员每人的电脑是一个完整的版本库。如：A在自己电脑改了文件C，B也在自己电脑上改了文件C，此时，A和B只需把各自修改推送给对方，就可以看见对方的修改。 Git 安装 搜索git，进入(https://www.git-scm.com/download/)，点击下载 点击安装包，点击“下一步”，安装时选择“Use git from git bash only…”，其它默认 安装完后，检查是否已经配置环境变量 配置git用户名和邮箱 1234右键-git bashgit config --global user.name \"用户名\"git config --global user.email \"邮箱\"检查是否配置成功，查看C:\\User\\电脑登录名\\.gitconfig 为了在本地和远程仓库之间进行 免秘钥登录，可以配置ssh(具体可在网站搜索)) Git 常用操作 本地项目 -远程项目关联 12git init //本地项目文件夹右建-gitbashgit remote add origin github仓库名地址 第一次将本地代码发布到远程仓库 123git add . /git add file.txt //本地文件-本地暂存区,add 可以添加多个文件git commit -m '注释内容' //暂存区-本地分支仓库-默认master)git push -u origin master 第一次下载从远程仓库下载项目 1git clone 远程仓库.git 将本地代码提交到远程仓库 1234在当前项目文件夹-右键-git bashgit add .git commit -m '提交到分支' //git push origin master 将远程仓库的内容拉取到本地仓库分支 1git pull 12345678910git status //查看仓库的当前状态git log --pretty=oneline //查看历史记录commit_idgit reset --hard commit_id //返回到commit_id版本git reflog //记录命令历史git checkout -b dev分支 //创建dev分支并切换到dev分支git branch //列出所有分支git checkout master //切换到master分支git switch -c dev //创建并切换到新的dev分支git merge dev // 合并指定分支到当前分支git branch -d dev //删除dev分支 工作区(Working Directory)：项目文件夹 版本库(Repository):工作区有个隐藏的.git,是git的版本库。版本库中stage(或者叫index)的暂存区 把文件往git版本库里添加的时候，是分两步执行的： 用git add把文件添加进去，实际上就是把文件修改添加到暂存区 用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支","categories":[],"tags":[]},{"title":"关于我","slug":"about-me","date":"2019-10-19T09:06:41.000Z","updated":"2019-10-19T09:17:46.233Z","comments":true,"path":"2019/10/19/about-me/","link":"","permalink":"https://shuo0904.github.io/blog/2019/10/19/about-me/","excerpt":"","text":"平时喜欢整理个人博客，逛逛技术论坛。 了解一些 前端 基本概念和 Python 的简单用法。","categories":[],"tags":[]},{"title":"关于转载","slug":"copyright-reprinted","date":"2019-10-19T08:07:51.000Z","updated":"2019-10-19T09:05:06.844Z","comments":true,"path":"2019/10/19/copyright-reprinted/","link":"","permalink":"https://shuo0904.github.io/blog/2019/10/19/copyright-reprinted/","excerpt":"","text":"尊重原创，从我做起 😂 相互学习，欢迎转载，转载时请加上原文链接！","categories":[],"tags":[]}]}